# .env.example - LLM Code Assistant 環境変数設定例
# このファイルをコピーして .env ファイルを作成し、実際の値を設定してください

# =============================================================================
# アプリケーション基本設定
# =============================================================================

# アプリケーション名
APP_NAME=LLM Code Assistant

# 実行環境 (development, production, testing)
ENVIRONMENT=development

# デバッグモード (true/false)
DEBUG=true

# ログレベル (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# アプリケーションポート
PORT=8000

# ホスト設定
HOST=localhost

# =============================================================================
# データベース設定
# =============================================================================

# SQLiteデータベースファイルパス
DATABASE_URL=sqlite:///data/database/llm_assistant.db

# ベクターデータベース設定
VECTOR_DB_PATH=data/vector_db/
VECTOR_DB_TYPE=faiss

# 埋め込みモデル設定
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# =============================================================================
# LLM API設定
# =============================================================================

# OpenAI API設定
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OPENAI_BASE_URL=https://api.openai.com/v1

# Claude API設定
CLAUDE_API_KEY=your_claude_api_key_here
CLAUDE_MODEL=claude-3-sonnet-20240229
CLAUDE_MAX_TOKENS=4096
CLAUDE_TEMPERATURE=0.7
CLAUDE_BASE_URL=https://api.anthropic.com

# Azure OpenAI設定
AZURE_OPENAI_API_KEY=your_azure_openai_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# =============================================================================
# ローカルLLM設定
# =============================================================================

# ローカルLLMモデルパス
LOCAL_LLM_MODEL_PATH=models/
LOCAL_LLM_MODEL_NAME=codellama-7b-instruct.gguf

# Hugging Face設定
HUGGINGFACE_TOKEN=your_huggingface_token_here
HUGGINGFACE_CACHE_DIR=models/huggingface_cache/

# Ollama設定
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=codellama:7b-instruct

# LlamaCpp設定
LLAMACPP_MODEL_PATH=models/llama-2-7b-chat.gguf
LLAMACPP_N_CTX=4096
LLAMACPP_N_THREADS=8
LLAMACPP_N_GPU_LAYERS=0

# =============================================================================
# UI設定
# =============================================================================

# テーマ設定
DEFAULT_THEME=dark
THEME_PATH=assets/themes/

# フォント設定
EDITOR_FONT_FAMILY=Consolas
EDITOR_FONT_SIZE=12
UI_FONT_FAMILY=Yu Gothic UI
UI_FONT_SIZE=9

# ウィンドウ設定
WINDOW_WIDTH=1200
WINDOW_HEIGHT=800
WINDOW_MAXIMIZED=false

# =============================================================================
# ファイル・ディレクトリ設定
# =============================================================================

# プロジェクトルートディレクトリ
PROJECT_ROOT=./

# 設定ファイルディレクトリ
CONFIG_DIR=config/

# データディレクトリ
DATA_DIR=data/

# ログディレクトリ
LOG_DIR=logs/

# キャッシュディレクトリ
CACHE_DIR=cache/

# 一時ファイルディレクトリ
TEMP_DIR=temp/

# バックアップディレクトリ
BACKUP_DIR=backups/

# ユーザーデータディレクトリ
USER_DATA_DIR=user_data/

# =============================================================================
# セキュリティ設定
# =============================================================================

# 暗号化キー（32文字の英数字）
ENCRYPTION_KEY=your_32_character_encryption_key_here

# セッション設定
SESSION_SECRET_KEY=your_session_secret_key_here
SESSION_TIMEOUT=3600

# JWT設定
JWT_SECRET_KEY=your_jwt_secret_key_here
JWT_ALGORITHM=HS256
JWT_EXPIRATION=86400

# =============================================================================
# キャッシュ設定
# =============================================================================

# Redis設定（使用する場合）
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=

# メモリキャッシュ設定
MEMORY_CACHE_SIZE=1000
MEMORY_CACHE_TTL=3600

# ファイルキャッシュ設定
FILE_CACHE_ENABLED=true
FILE_CACHE_MAX_SIZE=500MB

# =============================================================================
# パフォーマンス設定
# =============================================================================

# ワーカープロセス数
WORKER_PROCESSES=4

# 最大同時接続数
MAX_CONNECTIONS=100

# タイムアウト設定
REQUEST_TIMEOUT=30
RESPONSE_TIMEOUT=60

# バッチサイズ
BATCH_SIZE=32

# =============================================================================
# プラグイン設定
# =============================================================================

# プラグインディレクトリ
PLUGIN_DIR=src/plugins/

# プラグイン自動読み込み
AUTO_LOAD_PLUGINS=true

# 有効なプラグイン（カンマ区切り）
ENABLED_PLUGINS=git_integration,code_formatter,export_tools

# =============================================================================
# Git統合設定
# =============================================================================

# Git実行ファイルパス
GIT_EXECUTABLE=git

# デフォルトブランチ名
DEFAULT_BRANCH=main

# 自動コミット設定
AUTO_COMMIT_ENABLED=false
AUTO_COMMIT_MESSAGE=Auto commit by LLM Code Assistant

# =============================================================================
# コードフォーマッター設定
# =============================================================================

# Python フォーマッター
PYTHON_FORMATTER=black
PYTHON_LINE_LENGTH=88

# JavaScript フォーマッター
JAVASCRIPT_FORMATTER=prettier
JAVASCRIPT_TAB_WIDTH=2

# HTML フォーマッター
HTML_FORMATTER=prettier
HTML_TAB_WIDTH=2

# =============================================================================
# エクスポート設定
# =============================================================================

# エクスポートディレクトリ
EXPORT_DIR=exports/

# デフォルトエクスポート形式
DEFAULT_EXPORT_FORMAT=pdf

# PDF設定
PDF_PAGE_SIZE=A4
PDF_MARGIN=20mm

# =============================================================================
# 監視・メトリクス設定
# =============================================================================

# メトリクス収集有効化
METRICS_ENABLED=true

# メトリクス出力間隔（秒）
METRICS_INTERVAL=60

# パフォーマンス監視
PERFORMANCE_MONITORING=true

# =============================================================================
# 外部サービス設定
# =============================================================================

# GitHub統合
GITHUB_TOKEN=your_github_token_here
GITHUB_USERNAME=your_github_username

# GitLab統合
GITLAB_TOKEN=your_gitlab_token_here
GITLAB_URL=https://gitlab.com

# Slack通知
SLACK_WEBHOOK_URL=your_slack_webhook_url_here
SLACK_CHANNEL=#llm-assistant

# Discord通知
DISCORD_WEBHOOK_URL=your_discord_webhook_url_here

# =============================================================================
# 開発・テスト設定
# =============================================================================

# テストデータベース
TEST_DATABASE_URL=sqlite:///data/test_database.db

# テスト用API設定
TEST_API_ENABLED=true
TEST_API_PORT=8001

# モックデータ使用
USE_MOCK_DATA=false

# デバッグ出力
VERBOSE_LOGGING=false

# プロファイリング有効化
PROFILING_ENABLED=false

# =============================================================================
# 高度な設定
# =============================================================================

# 並列処理設定
PARALLEL_PROCESSING=true
MAX_PARALLEL_TASKS=4

# メモリ制限
MAX_MEMORY_USAGE=2GB

# CPU使用率制限
MAX_CPU_USAGE=80

# ネットワーク設定
NETWORK_TIMEOUT=30
MAX_RETRIES=3

# =============================================================================
# 実験的機能
# =============================================================================

# 実験的機能有効化
EXPERIMENTAL_FEATURES=false

# ベータ機能
BETA_FEATURES=false

# 新機能プレビュー
PREVIEW_FEATURES=false

# =============================================================================
# 注意事項
# =============================================================================
#
# 1. このファイルは設定例です。実際の値は .env ファイルに設定してください
# 2. APIキーなどの機密情報は絶対にバージョン管理に含めないでください
# 3. 本番環境では適切なセキュリティ設定を行ってください
# 4. 設定値を変更した場合は、アプリケーションの再起動が必要です
# 5. 一部の設定は実行時に動的に変更可能です
#
