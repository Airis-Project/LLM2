{
  "version": "1.0.0",
  "application": {
    "name": "LLM Chat System - Multi-Provider Configuration",
    "debug": false,
    "log_level": "INFO"
  },
  "llm": {
    "default_provider": "openai",
    "timeout": 30,
    "max_retries": 3,
    "providers": {
      "openai": {
        "enabled": true,
        "api_key": "${OPENAI_API_KEY}",
        "organization": "${OPENAI_ORG_ID}",
        "models": {
          "default": "gpt-4",
          "available": ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"]
        },
        "parameters": {
          "temperature": 0.7,
          "max_tokens": 2000
        }
      },
      "anthropic": {
        "enabled": true,
        "api_key": "${ANTHROPIC_API_KEY}",
        "models": {
          "default": "claude-3-sonnet-20240229",
          "available": [
            "claude-3-haiku-20240307",
            "claude-3-sonnet-20240229",
            "claude-3-opus-20240229"
          ]
        },
        "parameters": {
          "temperature": 0.7,
          "max_tokens": 2000
        }
      }
    }
  },
  "ui": {
    "default_interface": "cli",
    "cli": {
      "prompt_style": "colorful",
      "show_timestamps": true,
      "auto_complete": true
    }
  },
  "logging": {
    "level": "INFO",
    "console_output": true,
    "file_output": true
  },
  "security": {
    "api_key_validation": true,
    "rate_limiting": {
      "enabled": true,
      "requests_per_minute": 60
    }
  }
}
