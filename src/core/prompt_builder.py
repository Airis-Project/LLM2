# src/core/prompt_builder.py
"""
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚·ã‚¹ãƒ†ãƒ 
LLMã¸ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹•çš„ã«æ§‹ç¯‰ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ€é©åŒ–ã™ã‚‹
"""

import logging
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
from enum import Enum

class PromptType(Enum):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã®å®šç¾©"""
    CODE_GENERATION = "code_generation"
    CODE_REVIEW = "code_review"
    CODE_DEBUG = "code_debug"
    CODE_EXPLANATION = "code_explanation"
    CODE_REFACTOR = "code_refactor"
    DOCUMENTATION = "documentation"
    TESTING = "testing"
    GENERAL_CHAT = "general_chat"
    PROJECT_ANALYSIS = "project_analysis"
    ERROR_ANALYSIS = "error_analysis"

class PromptBuilder:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚¯ãƒ©ã‚¹
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€é©ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            config: è¨­å®šè¾æ›¸
        """
        self.logger = logging.getLogger(__name__)
        self.config = config or {}
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self.max_context_length = self.config.get('max_context_length', 8000)
        self.max_code_examples = self.config.get('max_code_examples', 3)
        self.include_file_structure = self.config.get('include_file_structure', True)
        self.language_preference = self.config.get('language_preference', 'japanese')
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.templates = self._load_prompt_templates()
        
        self.logger.info("PromptBuilderåˆæœŸåŒ–å®Œäº†")
    
    def build_prompt(self, 
                    user_query: str,
                    prompt_type: PromptType,
                    context_chunks: List[Dict[str, Any]] = None,
                    project_info: Dict[str, Any] = None,
                    conversation_history: List[Dict[str, str]] = None) -> str:
        """
        ãƒ¡ã‚¤ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            user_query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            prompt_type: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—
            context_chunks: é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ãƒãƒ£ãƒ³ã‚¯
            project_info: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            conversation_history: ä¼šè©±å±¥æ­´
            
        Returns:
            æ§‹ç¯‰ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        try:
            self.logger.debug(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰é–‹å§‹: {prompt_type.value}")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŸºæœ¬æ§‹é€ ã‚’æ§‹ç¯‰
            prompt_parts = []
            
            # 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt = self._build_system_prompt(prompt_type, project_info)
            prompt_parts.append(system_prompt)
            
            # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            if context_chunks:
                context_section = self._build_context_section(context_chunks)
                prompt_parts.append(context_section)
            
            # 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            if project_info and self.include_file_structure:
                project_section = self._build_project_section(project_info)
                prompt_parts.append(project_section)
            
            # 4. ä¼šè©±å±¥æ­´
            if conversation_history:
                history_section = self._build_history_section(conversation_history)
                prompt_parts.append(history_section)
            
            # 5. ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æŒ‡ç¤º
            task_instructions = self._build_task_instructions(prompt_type, user_query)
            prompt_parts.append(task_instructions)
            
            # 6. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒª
            query_section = self._build_query_section(user_query, prompt_type)
            prompt_parts.append(query_section)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆ
            full_prompt = "\n\n".join(filter(None, prompt_parts))
            
            # é•·ã•åˆ¶é™ã®é©ç”¨
            optimized_prompt = self._optimize_prompt_length(full_prompt)
            
            self.logger.debug(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº†: {len(optimized_prompt)}æ–‡å­—")
            return optimized_prompt
            
        except Exception as e:
            self.logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            return self._build_fallback_prompt(user_query, prompt_type)
    
    def _build_system_prompt(self, prompt_type: PromptType, project_info: Dict[str, Any] = None) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        base_system = """ã‚ãªãŸã¯é«˜åº¦ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š

ğŸ¯ **å°‚é–€æ€§**
- è¤‡æ•°ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ç²¾é€š
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çŸ¥è­˜
- ã‚³ãƒ¼ãƒ‰ã®å“è³ªã€æ€§èƒ½ã€ä¿å®ˆæ€§ã‚’é‡è¦–

ğŸ’¡ **å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«**
- æ˜ç¢ºã§å®Ÿç”¨çš„ãªå›ç­”
- å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ä¾‹ã®æä¾›
- ç†ç”±ã¨æ ¹æ‹ ã®èª¬æ˜
- æ—¥æœ¬èªã§ã®ä¸å¯§ãªèª¬æ˜

ğŸ”§ **å¯¾å¿œç¯„å›²**
- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»ä¿®æ­£ãƒ»ãƒ‡ãƒãƒƒã‚°
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã®ææ¡ˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ãƒ†ã‚¹ãƒˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ"""
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ã®è¿½åŠ æŒ‡ç¤º
        type_specific = self.templates.get('system', {}).get(prompt_type.value, "")
        
        if type_specific:
            base_system += f"\n\n**ä»Šå›ã®ã‚¿ã‚¹ã‚¯**: {type_specific}"
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®æƒ…å ±
        if project_info:
            project_context = self._format_project_context(project_info)
            if project_context:
                base_system += f"\n\n**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±**:\n{project_context}"
        
        return base_system
    
    def _build_context_section(self, context_chunks: List[Dict[str, Any]]) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰"""
        if not context_chunks:
            return ""
        
        context_parts = ["## ğŸ“ é–¢é€£ã‚³ãƒ¼ãƒ‰æƒ…å ±"]
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚’é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_chunks = self._sort_chunks_by_relevance(context_chunks)
        
        # æœ€å¤§æ•°ã¾ã§å‡¦ç†
        for i, chunk in enumerate(sorted_chunks[:self.max_code_examples]):
            chunk_section = self._format_chunk(chunk, i + 1)
            context_parts.append(chunk_section)
        
        return "\n\n".join(context_parts)
    
    def _build_project_section(self, project_info: Dict[str, Any]) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰"""
        if not project_info:
            return ""
        
        section_parts = ["## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ "]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 
        if 'file_structure' in project_info:
            structure = project_info['file_structure']
            section_parts.append(f"```\n{structure}\n```")
        
        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
        if 'tech_stack' in project_info:
            tech_info = project_info['tech_stack']
            tech_text = self._format_tech_stack(tech_info)
            section_parts.append(f"**æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯**: {tech_text}")
        
        # è¨­å®šæƒ…å ±
        if 'config_summary' in project_info:
            config_info = project_info['config_summary']
            section_parts.append(f"**è¨­å®šæƒ…å ±**: {config_info}")
        
        return "\n\n".join(section_parts)
    
    def _build_history_section(self, conversation_history: List[Dict[str, str]]) -> str:
        """ä¼šè©±å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰"""
        if not conversation_history:
            return ""
        
        # æœ€è¿‘ã®ä¼šè©±ã®ã¿ã‚’å«ã‚ã‚‹ï¼ˆæœ€å¤§5ä»¶ï¼‰
        recent_history = conversation_history[-5:]
        
        history_parts = ["## ğŸ’¬ ä¼šè©±å±¥æ­´"]
        
        for i, exchange in enumerate(recent_history, 1):
            user_msg = exchange.get('user', '')
            assistant_msg = exchange.get('assistant', '')
            
            if user_msg:
                history_parts.append(f"**Q{i}**: {user_msg[:200]}...")
            if assistant_msg:
                history_parts.append(f"**A{i}**: {assistant_msg[:200]}...")
        
        return "\n\n".join(history_parts)
    
    def _build_task_instructions(self, prompt_type: PromptType, user_query: str) -> str:
        """ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æŒ‡ç¤ºã‚’æ§‹ç¯‰"""
        instructions = self.templates.get('instructions', {}).get(prompt_type.value, "")
        
        if not instructions:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæŒ‡ç¤º
            if prompt_type == PromptType.CODE_GENERATION:
                instructions = "æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã€å®Ÿç”¨çš„ã§å‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            elif prompt_type == PromptType.CODE_DEBUG:
                instructions = "ã‚³ãƒ¼ãƒ‰ã®å•é¡Œã‚’ç‰¹å®šã—ã€ä¿®æ­£æ¡ˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼ã®åŸå› ã¨è§£æ±ºæ–¹æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            elif prompt_type == PromptType.CODE_REVIEW:
                instructions = "ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€æ”¹å–„ç‚¹ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚å“è³ªã€æ€§èƒ½ã€ä¿å®ˆæ€§ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
            else:
                instructions = "è³ªå•ã«å¯¾ã—ã¦é©åˆ‡ã§å®Ÿç”¨çš„ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
        
        # ã‚¯ã‚¨ãƒªã‹ã‚‰ç‰¹å®šã®è¨€èªã‚„æŠ€è¡“ã‚’æ¤œå‡º
        detected_tech = self._detect_technologies(user_query)
        if detected_tech:
            tech_instruction = f"\n\n**æ¤œå‡ºã•ã‚ŒãŸæŠ€è¡“**: {', '.join(detected_tech)}\nã“ã‚Œã‚‰ã®æŠ€è¡“ã«ç‰¹åŒ–ã—ãŸå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            instructions += tech_instruction
        
        return f"## ğŸ¯ ã‚¿ã‚¹ã‚¯æŒ‡ç¤º\n{instructions}"
    
    def _build_query_section(self, user_query: str, prompt_type: PromptType) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰"""
        query_parts = ["## â“ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•"]
        
        # ã‚¯ã‚¨ãƒªã®åˆ†æ
        query_analysis = self._analyze_query(user_query)
        
        # ãƒ¡ã‚¤ãƒ³ã‚¯ã‚¨ãƒª
        query_parts.append(f"**è³ªå•å†…å®¹**: {user_query}")
        
        # åˆ†æçµæœ
        if query_analysis:
            query_parts.append(f"**åˆ†æçµæœ**: {query_analysis}")
        
        # æœŸå¾…ã•ã‚Œã‚‹å›ç­”å½¢å¼
        expected_format = self._get_expected_format(prompt_type)
        if expected_format:
            query_parts.append(f"**æœŸå¾…ã•ã‚Œã‚‹å›ç­”å½¢å¼**: {expected_format}")
        
        return "\n\n".join(query_parts)
    
    def _format_chunk(self, chunk: Dict[str, Any], index: int) -> str:
        """ãƒãƒ£ãƒ³ã‚¯ã‚’æ•´å½¢"""
        chunk_parts = [f"### ğŸ“„ ã‚³ãƒ¼ãƒ‰ä¾‹ {index}"]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
        file_path = chunk.get('file_path', 'unknown')
        file_name = Path(file_path).name
        language = chunk.get('language', 'text')
        
        chunk_parts.append(f"**ãƒ•ã‚¡ã‚¤ãƒ«**: `{file_name}` ({language})")
        
        # è¡Œæƒ…å ±
        line_start = chunk.get('line_start', 1)
        line_end = chunk.get('line_end', 1)
        chunk_parts.append(f"**è¡Œç¯„å›²**: {line_start}-{line_end}")
        
        # é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹æƒ…å ±
        if chunk.get('function_name'):
            chunk_parts.append(f"**é–¢æ•°**: `{chunk['function_name']}`")
        if chunk.get('class_name'):
            chunk_parts.append(f"**ã‚¯ãƒ©ã‚¹**: `{chunk['class_name']}`")
        
        # docstring
        if chunk.get('docstring'):
            chunk_parts.append(f"**èª¬æ˜**: {chunk['docstring'][:100]}...")
        
        # ã‚³ãƒ¼ãƒ‰å†…å®¹
        content = chunk.get('content', '')
        if content:
            chunk_parts.append(f"```{language}\n{content}\n```")
        
        return "\n".join(chunk_parts)
    
    def _format_project_context(self, project_info: Dict[str, Any]) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’æ•´å½¢"""
        context_parts = []
        
        if 'name' in project_info:
            context_parts.append(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project_info['name']}")
        
        if 'description' in project_info:
            context_parts.append(f"èª¬æ˜: {project_info['description']}")
        
        if 'main_language' in project_info:
            context_parts.append(f"ä¸»è¦è¨€èª: {project_info['main_language']}")
        
        return "\n".join(context_parts)
    
    def _format_tech_stack(self, tech_stack: Dict[str, Any]) -> str:
        """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ•´å½¢"""
        tech_parts = []
        
        for category, technologies in tech_stack.items():
            if isinstance(technologies, list):
                tech_list = ", ".join(technologies)
                tech_parts.append(f"{category}: {tech_list}")
            else:
                tech_parts.append(f"{category}: {technologies}")
        
        return " | ".join(tech_parts)
    
    def _sort_chunks_by_relevance(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒãƒ£ãƒ³ã‚¯ã‚’é–¢é€£åº¦é †ã«ã‚½ãƒ¼ãƒˆ"""
        # ç°¡å˜ãªé–¢é€£åº¦è¨ˆç®—ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨å¯èƒ½ï¼‰
        def relevance_score(chunk):
            score = 0
            
            # é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹ã¯é«˜ã‚¹ã‚³ã‚¢
            if chunk.get('function_name'):
                score += 10
            if chunk.get('class_name'):
                score += 8
            
            # docstringãŒã‚ã‚‹ã‚‚ã®ã¯é«˜ã‚¹ã‚³ã‚¢
            if chunk.get('docstring'):
                score += 5
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã¯ä½ã‚¹ã‚³ã‚¢
            if chunk.get('type') == 'imports':
                score += 1
            
            # ã‚³ãƒ¼ãƒ‰é‡ã«ã‚ˆã‚‹èª¿æ•´
            content_length = len(chunk.get('content', ''))
            if 100 < content_length < 1000:  # é©åº¦ãªé•·ã•
                score += 3
            elif content_length > 1000:  # é•·ã™ãã‚‹
                score -= 2
            
            return score
        
        return sorted(chunks, key=relevance_score, reverse=True)
    
    def _detect_technologies(self, query: str) -> List[str]:
        """ã‚¯ã‚¨ãƒªã‹ã‚‰æŠ€è¡“ã‚’æ¤œå‡º"""
        technologies = {
            'python': ['python', 'py', 'django', 'flask', 'fastapi', 'pandas', 'numpy'],
            'javascript': ['javascript', 'js', 'node', 'react', 'vue', 'angular', 'express'],
            'typescript': ['typescript', 'ts'],
            'java': ['java', 'spring', 'maven', 'gradle'],
            'cpp': ['c++', 'cpp', 'cmake'],
            'c': ['cè¨€èª', 'c'],
            'database': ['sql', 'mysql', 'postgresql', 'mongodb', 'database', 'db'],
            'web': ['html', 'css', 'web', 'api', 'rest', 'graphql'],
            'devops': ['docker', 'kubernetes', 'aws', 'azure', 'gcp', 'ci/cd'],
            'testing': ['test', 'unittest', 'pytest', 'jest', 'testing']
        }
        
        detected = []
        query_lower = query.lower()
        
        for tech_category, keywords in technologies.items():
            for keyword in keywords:
                if keyword in query_lower:
                    detected.append(tech_category)
                    break
        
        return list(set(detected))
    
    def _analyze_query(self, query: str) -> str:
        """ã‚¯ã‚¨ãƒªã‚’åˆ†æ"""
        analysis_parts = []
        
        # è³ªå•ã‚¿ã‚¤ãƒ—ã®æ¤œå‡º
        if any(word in query.lower() for word in ['ãªãœ', 'why', 'ç†ç”±', 'åŸå› ']):
            analysis_parts.append("èª¬æ˜ãƒ»ç†ç”±ã‚’æ±‚ã‚ã‚‹è³ªå•")
        
        if any(word in query.lower() for word in ['ã©ã†ã‚„ã£ã¦', 'how', 'æ–¹æ³•', 'ã‚„ã‚Šæ–¹']):
            analysis_parts.append("æ‰‹é †ãƒ»æ–¹æ³•ã‚’æ±‚ã‚ã‚‹è³ªå•")
        
        if any(word in query.lower() for word in ['ã‚¨ãƒ©ãƒ¼', 'error', 'ãƒã‚°', 'bug', 'å‹•ã‹ãªã„']):
            analysis_parts.append("ã‚¨ãƒ©ãƒ¼ãƒ»ãƒ‡ãƒãƒƒã‚°é–¢é€£")
        
        if any(word in query.lower() for word in ['æœ€é©åŒ–', 'optimize', 'æ”¹å–„', 'improve', 'é«˜é€ŸåŒ–']):
            analysis_parts.append("æœ€é©åŒ–ãƒ»æ”¹å–„é–¢é€£")
        
        if any(word in query.lower() for word in ['ä½œæˆ', 'create', 'ç”Ÿæˆ', 'generate', 'æ›¸ã„ã¦']):
            analysis_parts.append("ã‚³ãƒ¼ãƒ‰ç”Ÿæˆè¦æ±‚")
        
        return " | ".join(analysis_parts) if analysis_parts else "ä¸€èˆ¬çš„ãªè³ªå•"
    
    def _get_expected_format(self, prompt_type: PromptType) -> str:
        """æœŸå¾…ã•ã‚Œã‚‹å›ç­”å½¢å¼ã‚’å–å¾—"""
        format_map = {
            PromptType.CODE_GENERATION: "å‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ + èª¬æ˜ + ä½¿ç”¨ä¾‹",
            PromptType.CODE_DEBUG: "å•é¡Œã®ç‰¹å®š + ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ + èª¬æ˜",
            PromptType.CODE_REVIEW: "è©•ä¾¡ãƒã‚¤ãƒ³ãƒˆ + æ”¹å–„ææ¡ˆ + ä¿®æ­£ä¾‹",
            PromptType.CODE_EXPLANATION: "ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œèª¬æ˜ + é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ",
            PromptType.DOCUMENTATION: "æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ + ä¾‹",
            PromptType.TESTING: "ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ + ãƒ†ã‚¹ãƒˆæˆ¦ç•¥",
            PromptType.ERROR_ANALYSIS: "ã‚¨ãƒ©ãƒ¼åŸå›  + è§£æ±ºæ‰‹é † + äºˆé˜²ç­–"
        }
        
        return format_map.get(prompt_type, "é©åˆ‡ãªå½¢å¼ã§ã®å›ç­”")
    
    def _optimize_prompt_length(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã‚’æœ€é©åŒ–"""
        if len(prompt) <= self.max_context_length:
            return prompt
        
        self.logger.warning(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã™ãã¾ã™ ({len(prompt)} > {self.max_context_length})")
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«å„ªå…ˆåº¦ã‚’è¨­å®šã—ã¦å‰Šæ¸›
        sections = prompt.split('\n\n')
        
        # é‡è¦åº¦ã®é«˜ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿æŒ
        essential_sections = []
        optional_sections = []
        
        for section in sections:
            if any(marker in section for marker in ['## â“', '## ğŸ¯', 'ã‚·ã‚¹ãƒ†ãƒ ']):
                essential_sections.append(section)
            else:
                optional_sections.append(section)
        
        # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰é–‹å§‹
        optimized_prompt = '\n\n'.join(essential_sections)
        
        # æ®‹ã‚Šã®é•·ã•ã§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        remaining_length = self.max_context_length - len(optimized_prompt)
        
        for section in optional_sections:
            if len(section) < remaining_length:
                optimized_prompt += '\n\n' + section
                remaining_length -= len(section) + 2
            else:
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’çŸ­ç¸®
                truncated = section[:remaining_length-100] + "\n...(çœç•¥)"
                optimized_prompt += '\n\n' + truncated
                break
        
        self.logger.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–å®Œäº†: {len(prompt)} -> {len(optimized_prompt)}")
        return optimized_prompt
    
    def _build_fallback_prompt(self, user_query: str, prompt_type: PromptType) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return f"""ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

è³ªå•: {user_query}

ä¸Šè¨˜ã®è³ªå•ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®ç‚¹ã‚’è€ƒæ…®ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
- å®Ÿç”¨çš„ã§å…·ä½“çš„ãªå›ç­”
- å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã‚‹
- æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«åŸºã¥ãææ¡ˆ

å›ç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"""
    
    def _load_prompt_templates(self) -> Dict[str, Dict[str, str]]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        templates = {
            'system': {
                'code_generation': "æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚è¦ä»¶ã‚’åˆ†æã—ã€åŠ¹ç‡çš„ã§ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
                'code_debug': "ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒãƒƒã‚°ã¨ã‚¨ãƒ©ãƒ¼è§£æ±ºã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚å•é¡Œã‚’ç‰¹å®šã—ã€å…·ä½“çš„ãªä¿®æ­£æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚",
                'code_review': "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚å“è³ªã€æ€§èƒ½ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã€æ”¹å–„ææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚",
                'code_explanation': "ã‚³ãƒ¼ãƒ‰ã®è§£èª¬ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚è¤‡é›‘ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã€å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚",
                'documentation': "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚æŠ€è¡“æ–‡æ›¸ã€APIä»•æ§˜ã€ä½¿ç”¨æ–¹æ³•ã‚’æ˜ç¢ºã«è¨˜è¿°ã—ã¾ã™ã€‚",
                'testing': "ãƒ†ã‚¹ãƒˆè¨­è¨ˆã¨å®Ÿè£…ã«ç‰¹åŒ–ã—ã¦ã„ã¾ã™ã€‚åŠ¹æœçš„ãªãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã¨ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã¾ã™ã€‚"
            },
            'instructions': {
                'code_generation': """ä»¥ä¸‹ã®æ‰‹é †ã§ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
1. è¦ä»¶ã®åˆ†æã¨æ•´ç†
2. é©åˆ‡ãªè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®é¸æŠ
3. å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆ
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®è¿½åŠ 
5. ã‚³ãƒ¡ãƒ³ãƒˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¨˜è¿°
6. ä½¿ç”¨ä¾‹ã®æä¾›""",
                
                'code_debug': """ä»¥ä¸‹ã®æ‰‹é †ã§ãƒ‡ãƒãƒƒã‚°ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
1. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆ†æ
2. å•é¡Œç®‡æ‰€ã®ç‰¹å®š
3. æ ¹æœ¬åŸå› ã®èª¿æŸ»
4. ä¿®æ­£æ–¹æ³•ã®ææ¡ˆ
5. ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã®æä¾›
6. å†ç™ºé˜²æ­¢ç­–ã®ææ¡ˆ""",
                
                'code_review': """ä»¥ä¸‹ã®è¦³ç‚¹ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ï¼š
1. ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§ã¨ä¿å®ˆæ€§
2. æ€§èƒ½ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è€ƒæ…®
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
5. ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£
6. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®éµå®ˆ"""
            }
        }
        
        return templates
    
    def create_specialized_prompt(self, 
                                 prompt_type: PromptType,
                                 specific_context: Dict[str, Any]) -> str:
        """ç‰¹æ®Šç”¨é€”å‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        
        if prompt_type == PromptType.PROJECT_ANALYSIS:
            return self._create_project_analysis_prompt(specific_context)
        elif prompt_type == PromptType.ERROR_ANALYSIS:
            return self._create_error_analysis_prompt(specific_context)
        else:
            return self._build_fallback_prompt(
                specific_context.get('query', ''), 
                prompt_type
            )
    
    def _create_project_analysis_prompt(self, context: Dict[str, Any]) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        prompt = """# ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æã‚¿ã‚¹ã‚¯

ã‚ãªãŸã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã¨ã—ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ä½“çš„ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

## åˆ†æå¯¾è±¡
"""
        
        if 'file_list' in context:
            prompt += f"**ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(context['file_list'])} å€‹\n"
        
        if 'languages' in context:
            prompt += f"**ä½¿ç”¨è¨€èª**: {', '.join(context['languages'])}\n"
        
        if 'project_structure' in context:
            prompt += f"**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ **:\n```\n{context['project_structure']}\n```\n"
        
        prompt += """
## åˆ†æé …ç›®
ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¦ãã ã•ã„ï¼š

1. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©•ä¾¡**
   - è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½¿ç”¨çŠ¶æ³
   - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®ä¾å­˜é–¢ä¿‚
   - æ‹¡å¼µæ€§ã¨ä¿å®ˆæ€§

2. **ã‚³ãƒ¼ãƒ‰å“è³ª**
   - ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã®éµå®ˆ
   - ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
   - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–çŠ¶æ³

3. **æŠ€è¡“çš„è² å‚µ**
   - æ”¹å–„ãŒå¿…è¦ãªç®‡æ‰€
   - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å€™è£œ
   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®æ‡¸å¿µ

4. **æ”¹å–„ææ¡ˆ**
   - å„ªå…ˆåº¦ä»˜ãã®æ”¹å–„æ¡ˆ
   - å®Ÿè£…æ–¹æ³•ã®ææ¡ˆ
   - æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

è©³ç´°ãªåˆ†æçµæœã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return prompt
    
    def _create_error_analysis_prompt(self, context: Dict[str, Any]) -> str:
        """ã‚¨ãƒ©ãƒ¼åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        prompt = """# ğŸš¨ ã‚¨ãƒ©ãƒ¼åˆ†æãƒ»è§£æ±ºã‚¿ã‚¹ã‚¯

ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã®åˆ†æã¨è§£æ±ºç­–ã®ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

## ã‚¨ãƒ©ãƒ¼æƒ…å ±
"""
        
        if 'error_message' in context:
            prompt += f"**ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**:\n```\n{context['error_message']}\n```\n\n"
        
        if 'stack_trace' in context:
            prompt += f"**ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹**:\n```\n{context['stack_trace']}\n```\n\n"
        
        if 'error_context' in context:
            prompt += f"**ç™ºç”ŸçŠ¶æ³**: {context['error_context']}\n\n"
        
        prompt += """## åˆ†æãƒ»è§£æ±ºæ‰‹é †

ä»¥ä¸‹ã®æ‰‹é †ã§åˆ†æã—ã¦ãã ã•ã„ï¼š

1. **ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡**
   - ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã¨é‡è¦åº¦
   - å½±éŸ¿ç¯„å›²ã®ç‰¹å®š

2. **åŸå› åˆ†æ**
   - ç›´æ¥çš„ãªåŸå› 
   - æ ¹æœ¬çš„ãªåŸå› 
   - é–¢é€£ã™ã‚‹è¦å› 

3. **è§£æ±ºç­–ã®ææ¡ˆ**
   - å³åº§ã«é©ç”¨å¯èƒ½ãªä¿®æ­£
   - æ ¹æœ¬çš„ãªè§£æ±ºæ–¹æ³•
   - ä»£æ›¿æ¡ˆã®æ¤œè¨

4. **äºˆé˜²ç­–**
   - å†ç™ºé˜²æ­¢ã®ãŸã‚ã®å¯¾ç­–
   - ç›£è¦–ãƒ»æ¤œçŸ¥ã®æ”¹å–„
   - ãƒ—ãƒ­ã‚»ã‚¹ã®è¦‹ç›´ã—

å®Ÿç”¨çš„ã§å…·ä½“çš„ãªè§£æ±ºç­–ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return prompt
    
    def validate_prompt(self, prompt: str) -> Tuple[bool, List[str]]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
        issues = []
        
        # é•·ã•ãƒã‚§ãƒƒã‚¯
        if len(prompt) > self.max_context_length:
            issues.append(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã™ãã¾ã™: {len(prompt)} > {self.max_context_length}")
        
        # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèª
        required_sections = ['è³ªå•', 'ã‚¿ã‚¹ã‚¯']
        for section in required_sections:
            if section not in prompt:
                issues.append(f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
        try:
            prompt.encode('utf-8')
        except UnicodeEncodeError:
            issues.append("æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼")
        
        return len(issues) == 0, issues
    
    def get_prompt_statistics(self, prompt: str) -> Dict[str, Any]:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        lines = prompt.split('\n')
        words = prompt.split()
        
        return {
            'character_count': len(prompt),
            'line_count': len(lines),
            'word_count': len(words),
            'section_count': prompt.count('##'),
            'code_block_count': prompt.count('```'),
            'estimated_tokens': len(words) * 1.3,  # æ¦‚ç®—
            'complexity_score': self._calculate_complexity_score(prompt)
        }
    
    def _calculate_complexity_score(self, prompt: str) -> float:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0.0
        
        # é•·ã•ã«ã‚ˆã‚‹åŸºæœ¬ã‚¹ã‚³ã‚¢
        score += len(prompt) / 1000
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°
        score += prompt.count('##') * 0.5
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æ•°
        score += prompt.count('```') * 0.3
        
        # å°‚é–€ç”¨èªã®ä½¿ç”¨
        technical_terms = ['API', 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', 'ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯']
        for term in technical_terms:
            if term in prompt:
                score += 0.1
        
        return round(score, 2)
    
    def export_prompt_template(self, prompt_type: PromptType, file_path: str) -> bool:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            template_data = {
                'type': prompt_type.value,
                'system_prompt': self.templates.get('system', {}).get(prompt_type.value, ''),
                'instructions': self.templates.get('instructions', {}).get(prompt_type.value, ''),
                'created_at': datetime.now().isoformat(),
                'config': {
                    'max_context_length': self.max_context_length,
                    'max_code_examples': self.max_code_examples,
                    'language_preference': self.language_preference
                }
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(template_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {file_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def __str__(self) -> str:
        return f"PromptBuilder(max_length={self.max_context_length}, templates={len(self.templates)})"


# ä½¿ç”¨ä¾‹
def example_usage():
    """PromptBuilderã®ä½¿ç”¨ä¾‹"""
    
    # åˆæœŸåŒ–
    config = {
        'max_context_length': 6000,
        'max_code_examples': 2,
        'language_preference': 'japanese'
    }
    
    builder = PromptBuilder(config)
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    context_chunks = [
        {
            'content': 'def calculate_sum(numbers):\n    return sum(numbers)',
            'type': 'function',
            'file_path': 'utils.py',
            'function_name': 'calculate_sum',
            'language': 'python',
            'line_start': 1,
            'line_end': 2
        }
    ]
    
    project_info = {
        'name': 'Sample Project',
        'main_language': 'Python',
        'tech_stack': {
            'backend': ['Python', 'FastAPI'],
            'database': ['PostgreSQL']
        }
    }
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    user_query = "ã“ã®é–¢æ•°ã‚’æ”¹å–„ã—ã¦ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ã—ã¦ãã ã•ã„"
    
    prompt = builder.build_prompt(
        user_query=user_query,
        prompt_type=PromptType.CODE_REVIEW,
        context_chunks=context_chunks,
        project_info=project_info
    )
    
    print("=== ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===")
    print(prompt)
    
    # çµ±è¨ˆæƒ…å ±
    stats = builder.get_prompt_statistics(prompt)
    print(f"\n=== çµ±è¨ˆæƒ…å ± ===")
    for key, value in stats.items():
        print(f"{key}: {value}")


if __name__ == "__main__":
    example_usage()
