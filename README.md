# LLM Code Assistant

![LLM Code Assistant Logo](assets/icons/app_icon.png)

[![Python Version](https://img.shields.io/badge/python-3.11+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](https://github.com/llm-code-assistant/llm-code-assistant)
[![Coverage](https://img.shields.io/badge/coverage-85%25-yellow.svg)](https://github.com/llm-code-assistant/llm-code-assistant)
[![Documentation](https://img.shields.io/badge/docs-latest-blue.svg)](https://llm-code-assistant.readthedocs.io/)

**LLM Code Assistant** ã¯ã€AI ã‚’æ´»ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»æ”¯æ´ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚OpenAI GPTã€Claudeã€ãƒ­ãƒ¼ã‚«ãƒ« LLM ãªã©è¤‡æ•°ã® AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€é–‹ç™ºè€…ã®ç”Ÿç”£æ€§å‘ä¸Šã‚’æ”¯æ´ã—ã¾ã™ã€‚

## âœ¨ ä¸»ãªæ©Ÿèƒ½

### ğŸ¤– ãƒãƒ«ãƒ LLM ã‚µãƒãƒ¼ãƒˆ
- **OpenAI GPT ã‚·ãƒªãƒ¼ã‚º**: GPT-4, GPT-3.5-turbo
- **Anthropic Claude**: Claude-3, Claude-2
- **ãƒ­ãƒ¼ã‚«ãƒ« LLM**: Llama, CodeLlama, ãã®ä»– Hugging Face ãƒ¢ãƒ‡ãƒ«
- **ã‚«ã‚¹ã‚¿ãƒ  API**: ç‹¬è‡ªã® LLM ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œ

### ğŸ’» é«˜æ©Ÿèƒ½ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
- ã‚·ãƒ³ã‚¿ãƒƒã‚¯ã‚¹ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆ100+ è¨€èªå¯¾å¿œï¼‰
- ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªã‚³ãƒ¼ãƒ‰è£œå®Œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼æ¤œå‡º
- Git çµ±åˆ
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†

### ğŸ¯ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆæ©Ÿèƒ½
- **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ**: è‡ªç„¶è¨€èªã‹ã‚‰ã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
- **ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼**: AI ã«ã‚ˆã‚‹å“è³ªãƒã‚§ãƒƒã‚¯
- **ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°**: ã‚³ãƒ¼ãƒ‰æ”¹å–„ææ¡ˆ
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ**: è‡ªå‹•ã‚³ãƒ¡ãƒ³ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
- **ãƒã‚°ä¿®æ­£**: ã‚¨ãƒ©ãƒ¼è§£æã¨ä¿®æ­£ææ¡ˆ

### ğŸ”§ é–‹ç™ºæ”¯æ´ãƒ„ãƒ¼ãƒ«
- **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†**: ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- **ã‚¹ãƒ‹ãƒšãƒƒãƒˆç®¡ç†**: å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¼ãƒ‰ç‰‡
- **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ **: æ©Ÿèƒ½æ‹¡å¼µå¯¾å¿œ
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»åŒæœŸ**: ã‚¯ãƒ©ã‚¦ãƒ‰é€£æº

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶
- **Python**: 3.11 ä»¥ä¸Š
- **OS**: Windows 10+, macOS 10.15+, Linux (Ubuntu 20.04+)
- **RAM**: 8GB ä»¥ä¸Šæ¨å¥¨ï¼ˆãƒ­ãƒ¼ã‚«ãƒ« LLM ä½¿ç”¨æ™‚ã¯ 16GB+ï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 2GB ä»¥ä¸Šã®ç©ºãå®¹é‡

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

#### æ–¹æ³• 1: pip ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæ¨å¥¨ï¼‰
```bash
# åŸºæœ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install llm-code-assistant

# å…¨æ©Ÿèƒ½ä»˜ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install llm-code-assistant[full]

# GPU ã‚µãƒãƒ¼ãƒˆä»˜ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install llm-code-assistant[gpu]

æ–¹æ³• 2: ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/llm-code-assistant/llm-code-assistant.git
cd llm-code-assistant

# ä»®æƒ³ç’°å¢ƒä½œæˆãƒ»æœ‰åŠ¹åŒ–
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -e .

æ–¹æ³• 3: Conda ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# Conda ç’°å¢ƒä½œæˆ
conda env create -f conda-environment.yml
conda activate llm-code-assistant

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
python -m src.main

åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
1.ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
    llm-code-assistant

2.API ã‚­ãƒ¼è¨­å®š
    è¨­å®š â†’ LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ â†’ API ã‚­ãƒ¼å…¥åŠ›
    OpenAI: sk-...
    Anthropic: sk-ant-...

3.åˆæœŸè¨­å®šå®Œäº†
    ãƒ†ãƒ¼ãƒé¸æŠ
    ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼è¨­å®š
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãƒ¼æŒ‡å®š

ğŸ“– ä½¿ç”¨æ–¹æ³•
åŸºæœ¬çš„ãªä½¿ã„æ–¹
1. ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹:
"Python ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ CSV ã¨ã—ã¦ä¿å­˜ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¦ãã ã•ã„"

ç”Ÿæˆã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰:
```python
import csv
import pandas as pd

def save_to_csv(data, filename):
    """ãƒ‡ãƒ¼ã‚¿ã‚’ CSV ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹é–¢æ•°"""
    try:
        df = pd.DataFrame(data)
        df.to_csv(filename, index=False, encoding='utf-8')
        print(f"ãƒ‡ãƒ¼ã‚¿ãŒ {filename} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        return True
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return False


#### 2. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼
- ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠ
- å³ã‚¯ãƒªãƒƒã‚¯ â†’ "AI ãƒ¬ãƒ“ãƒ¥ãƒ¼"
- å“è³ªãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è¦³ç‚¹ã‹ã‚‰åˆ†æ

#### 3. ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
- æ”¹å–„ã—ãŸã„ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠ
- Ctrl+Shift+R (Cmd+Shift+R)
- AI ãŒæœ€é©åŒ–æ¡ˆã‚’æç¤º

### é«˜åº¦ãªæ©Ÿèƒ½

#### ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
```yaml
# templates/python_class.yaml
name: "Python ã‚¯ãƒ©ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"
language: "python"
description: "åŸºæœ¬çš„ãª Python ã‚¯ãƒ©ã‚¹æ§‹é€ "
template: |
  class {{class_name}}:
      """{{description}}"""
      
      def __init__(self{{init_params}}):
          {{init_body}}
      
      def __str__(self):
          return f"{{class_name}}({{str_format}})"
      
      {{methods}}

variables:
  - name: "class_name"
    type: "string"
    required: true
  - name: "description"
    type: "string"
    default: "ã‚¯ãƒ©ã‚¹ã®èª¬æ˜"
  - name: "init_params"
    type: "string"
    default: ""

ãƒ—ãƒ©ã‚°ã‚¤ãƒ³é–‹ç™º
# plugins/my_plugin.py
from src.core.plugin_system import PluginBase

class MyPlugin(PluginBase):
    name = "My Custom Plugin"
    version = "1.0.0"
    
    def initialize(self):
        """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åˆæœŸåŒ–å‡¦ç†"""
        self.add_menu_item("Tools", "My Tool", self.run_tool)
    
    def run_tool(self):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ"""
        # ãƒ„ãƒ¼ãƒ«ã®å‡¦ç†ã‚’å®Ÿè£…
        pass

âš™ï¸ è¨­å®š
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
è¨­å®šã¯ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†ã•ã‚Œã¾ã™ï¼š
    config/default_config.json: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    config/user_settings.json: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
    config/logging_config.yaml: ãƒ­ã‚°è¨­å®š
    .env: ç’°å¢ƒå¤‰æ•°ï¼ˆAPI ã‚­ãƒ¼ãªã©ï¼‰

ä¸»è¦è¨­å®šé …ç›®
LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
{
  "llm": {
    "providers": {
      "openai": {
        "api_key": "your-api-key",
        "model": "gpt-4",
        "max_tokens": 2048,
        "temperature": 0.7
      },
      "claude": {
        "api_key": "your-api-key",
        "model": "claude-3-sonnet-20240229",
        "max_tokens": 4096
      },
      "local": {
        "model_path": "models/codellama-7b-instruct.gguf",
        "context_length": 4096,
        "gpu_layers": 32
      }
    }
  }
}

UI ãƒ†ãƒ¼ãƒè¨­å®š
{
  "ui": {
    "theme": {
      "current": "dark",
      "custom_themes": {
        "my_theme": {
          "background": "#1e1e1e",
          "foreground": "#d4d4d4",
          "accent": "#007acc"
        }
      }
    }
  }
}

ğŸ”Œ API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹
REST API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
POST /api/v1/generate
Content-Type: application/json

{
  "prompt": "Create a Python function to calculate fibonacci",
  "language": "python",
  "provider": "openai",
  "model": "gpt-4"
}

ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼
POST /api/v1/review
Content-Type: application/json

{
  "code": "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
  "language": "python",
  "review_type": "quality"
}

Python API
from llm_assistant import LLMAssistant

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
assistant = LLMAssistant()

# ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
result = assistant.generate_code(
    prompt="Create a REST API with FastAPI",
    language="python",
    provider="openai"
)

# ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼
review = assistant.review_code(
    code=my_code,
    language="python",
    focus=["security", "performance"]
)

ğŸ§ª ãƒ†ã‚¹ãƒˆ
ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ããƒ†ã‚¹ãƒˆ
pytest --cov=src --cov-report=html

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã®ã¿
pytest tests/test_llm_providers.py

# ãƒãƒ¼ã‚«ãƒ¼æŒ‡å®š
pytest -m "not slow"  # é‡ã„ãƒ†ã‚¹ãƒˆã‚’é™¤å¤–
pytest -m "integration"  # çµ±åˆãƒ†ã‚¹ãƒˆã®ã¿

ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒª
    Unit Tests: å˜ä½“ãƒ†ã‚¹ãƒˆ
    Integration Tests: çµ±åˆãƒ†ã‚¹ãƒˆ
    UI Tests: GUI ãƒ†ã‚¹ãƒˆ
    LLM Tests: AI æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    Performance Tests: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
# Sphinx ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
cd docs
make html

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚µãƒ¼ãƒãƒ¼èµ·å‹•
python -m http.server 8000 -d _build/html

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ§‹æˆ
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰: åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•
    é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: è©³ç´°ãª API ä»•æ§˜
    FAQ: ã‚ˆãã‚ã‚‹è³ªå•ã¨å›ç­”
ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³
é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# ãƒªãƒã‚¸ãƒˆãƒªãƒ•ã‚©ãƒ¼ã‚¯ãƒ»ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/yourusername/llm-code-assistant.git
cd llm-code-assistant

# é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
python -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt

# pre-commit ãƒ•ãƒƒã‚¯è¨­å®š
pre-commit install

ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
    Issue ä½œæˆ: ãƒã‚°å ±å‘Šãƒ»æ©Ÿèƒ½è¦æœ›
    ãƒ•ã‚©ãƒ¼ã‚¯: ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
    ãƒ–ãƒ©ãƒ³ãƒä½œæˆ: git checkout -b feature/your-feature
    é–‹ç™º: ã‚³ãƒ¼ãƒ‰ä½œæˆãƒ»ãƒ†ã‚¹ãƒˆè¿½åŠ 
    ãƒ†ã‚¹ãƒˆ: pytest ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    ã‚³ãƒŸãƒƒãƒˆ: git commit -m "Add: your feature"
    ãƒ—ãƒƒã‚·ãƒ¥: git push origin feature/your-feature
    ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: GitHub ã§ PR ä½œæˆ

ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„
    Python: PEP 8 æº–æ‹ 
    ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼: Black
    ãƒªãƒ³ã‚¿ãƒ¼: Flake8, Pylint
    å‹ãƒã‚§ãƒƒã‚¯: MyPy
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: Google ã‚¹ã‚¿ã‚¤ãƒ«

ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
ã‚ˆãã‚ã‚‹å•é¡Œ
1. API ã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼
Error: Invalid API key for OpenAI

è§£æ±ºæ–¹æ³•:

è¨­å®šç”»é¢ã§ API ã‚­ãƒ¼ã‚’ç¢ºèª
    .env ãƒ•ã‚¡ã‚¤ãƒ«ã® OPENAI_API_KEY ã‚’ç¢ºèª
    API ã‚­ãƒ¼ã®æ¨©é™ã‚’ç¢ºèª

2.ãƒ­ãƒ¼ã‚«ãƒ« LLM ãŒå‹•ä½œã—ãªã„
Error: Failed to load local model

è§£æ±ºæ–¹æ³•:

    ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèª
    ååˆ†ãªãƒ¡ãƒ¢ãƒªãŒã‚ã‚‹ã‹ç¢ºèª
    GPU ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æ›´æ–°ï¼ˆGPU ä½¿ç”¨æ™‚ï¼‰

3. UI ãŒè¡¨ç¤ºã•ã‚Œãªã„
Error: Qt platform plugin could not be initialized

è§£æ±ºæ–¹æ³•:
# Linux ã®å ´åˆ
sudo apt-get install python3-pyqt6

# macOS ã®å ´åˆ
brew install pyqt6

# Windows ã®å ´åˆ
pip uninstall PyQt6
pip install PyQt6

ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
ls logs/

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª
tail -f logs/error.log

# ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ç¢ºèª
tail -f logs/debug.log

ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT License ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

ğŸ™ è¬è¾
    OpenAI: GPT API ã®æä¾›
    Anthropic: Claude API ã®æä¾›
    Hugging Face: Transformers ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    Qt: GUI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼: å…¨ã¦ã®è²¢çŒ®è€…ã«æ„Ÿè¬
ğŸ“ ã‚µãƒãƒ¼ãƒˆ
ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
    GitHub Discussions: è³ªå•ãƒ»è­°è«–
    Discord: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒãƒ£ãƒƒãƒˆ
    Reddit: r/LLMCodeAssistant
å•†ç”¨ã‚µãƒãƒ¼ãƒˆ
    Email: support@llm-code-assistant.com
    Documentation: https://llm-code-assistant.readthedocs.io/
    Enterprise: enterprise@llm-code-assistant.com

ğŸ—ºï¸ ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
v1.1.0 (äºˆå®š)
    Visual Studio Code æ‹¡å¼µæ©Ÿèƒ½
    Jupyter Notebook çµ±åˆ
    éŸ³å£°å…¥åŠ›å¯¾å¿œ
    ãƒãƒ¼ãƒ æ©Ÿèƒ½
v1.2.0 (äºˆå®š)
    Web ãƒ–ãƒ©ã‚¦ã‚¶ç‰ˆ
    ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒª
    ã‚¯ãƒ©ã‚¦ãƒ‰åŒæœŸ
    é«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
v2.0.0 (äºˆå®š)
    ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« AI å¯¾å¿œ
    è‡ªå‹•ãƒ†ã‚¹ãƒˆç”Ÿæˆ
    CI/CD çµ±åˆ
    ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºæ©Ÿèƒ½

LLM Code Assistant - AI ã¨å…±ã«ã€ã‚ˆã‚Šè‰¯ã„ã‚³ãƒ¼ãƒ‰ã‚’ã€‚
